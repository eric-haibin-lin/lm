I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.7.5 locally
WARNING:tensorflow:From /home/ubuntu/lm/language_model.py:134 in _backward.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /home/ubuntu/lm/language_model.py:135 in _backward.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /home/ubuntu/lm/language_model.py:136 in _backward.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /home/ubuntu/lm/language_model.py:31 in __init__.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /home/ubuntu/lm/language_model.py:40 in __init__.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.merge_all.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.merge.
WARNING:tensorflow:From /home/ubuntu/lm/run_utils.py:17 in run_train.: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Please use tf.global_variables instead.
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py:344 in __init__.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:11.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x9b3b330
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:12.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0xa2945d0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 2 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:13.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x9c5a780
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 3 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:14.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x9c63f90
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 4 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:15.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x9cdbf50
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 5 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:16.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x9e60ee0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 6 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:17.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x9de5de0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 7 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:18.0
Total memory: 11.17GiB
Free memory: 11.11GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 2 3 4 5 6 7 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 2:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 3:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 4:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 5:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 6:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 7:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:11.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:00:12.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:00:13.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:00:14.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:4) -> (device: 4, name: Tesla K80, pci bus id: 0000:00:15.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:5) -> (device: 5, name: Tesla K80, pci bus id: 0000:00:16.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:6) -> (device: 6, name: Tesla K80, pci bus id: 0000:00:17.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:7) -> (device: 7, name: Tesla K80, pci bus id: 0000:00:18.0)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3052 get requests, put_count=2914 evicted_count=1000 eviction_rate=0.343171 and unsatisfied allocation rate=0.405636
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
waring: using single file
haibin overriding impl: Unique=True
haibin overriding impl: Unique=True
haibin overriding impl: Unique=True
haibin overriding impl: Unique=True
haibin overriding impl: Unique=True
haibin overriding impl: Unique=True
haibin overriding impl: Unique=True
haibin overriding impl: Unique=True
ALL VARIABLES
model/emb_0:0 (99184, 512) /gpu:0
model/emb_1:0 (99184, 512) /gpu:0
model/emb_2:0 (99184, 512) /gpu:0
model/emb_3:0 (99184, 512) /gpu:0
model/emb_4:0 (99184, 512) /gpu:0
model/emb_5:0 (99184, 512) /gpu:0
model/emb_6:0 (99184, 512) /gpu:0
model/emb_7:0 (99184, 512) /gpu:0
model/lstm_0/LSTMCell/W_0:0 (1024, 8192) /gpu:0
model/lstm_0/LSTMCell/B:0 (8192,) /gpu:0
model/lstm_0/LSTMCell/W_P_0:0 (2048, 512) /gpu:0
model/softmax_w_0:0 (99184, 512) /gpu:0
model/softmax_w_1:0 (99184, 512) /gpu:0
model/softmax_w_2:0 (99184, 512) /gpu:0
model/softmax_w_3:0 (99184, 512) /gpu:0
model/softmax_w_4:0 (99184, 512) /gpu:0
model/softmax_w_5:0 (99184, 512) /gpu:0
model/softmax_w_6:0 (99184, 512) /gpu:0
model/softmax_w_7:0 (99184, 512) /gpu:0
model/softmax_b:0 (793470,) /gpu:0
model/global_step:0 () 
model/model/emb_0/Adagrad:0 (99184, 512) /gpu:0
model/model/emb_1/Adagrad:0 (99184, 512) /gpu:0
model/model/emb_2/Adagrad:0 (99184, 512) /gpu:0
model/model/emb_3/Adagrad:0 (99184, 512) /gpu:0
model/model/emb_4/Adagrad:0 (99184, 512) /gpu:0
model/model/emb_5/Adagrad:0 (99184, 512) /gpu:0
model/model/emb_6/Adagrad:0 (99184, 512) /gpu:0
model/model/emb_7/Adagrad:0 (99184, 512) /gpu:0
model/model/lstm_0/LSTMCell/W_0/Adagrad:0 (1024, 8192) /gpu:0
model/model/lstm_0/LSTMCell/B/Adagrad:0 (8192,) /gpu:0
model/model/lstm_0/LSTMCell/W_P_0/Adagrad:0 (2048, 512) /gpu:0
model/model/softmax_w_0/Adagrad:0 (99184, 512) /gpu:0
model/model/softmax_w_1/Adagrad:0 (99184, 512) /gpu:0
model/model/softmax_w_2/Adagrad:0 (99184, 512) /gpu:0
model/model/softmax_w_3/Adagrad:0 (99184, 512) /gpu:0
model/model/softmax_w_4/Adagrad:0 (99184, 512) /gpu:0
model/model/softmax_w_5/Adagrad:0 (99184, 512) /gpu:0
model/model/softmax_w_6/Adagrad:0 (99184, 512) /gpu:0
model/model/softmax_w_7/Adagrad:0 (99184, 512) /gpu:0
model/model/softmax_b/Adagrad:0 (793470,) /gpu:0
model/lstm_0/LSTMCell/W_0/ExponentialMovingAverage:0 (1024, 8192) /gpu:0
model/lstm_0/LSTMCell/B/ExponentialMovingAverage:0 (8192,) /gpu:0
model/lstm_0/LSTMCell/W_P_0/ExponentialMovingAverage:0 (2048, 512) /gpu:0
TRAINABLE VARIABLES
model/emb_0:0 (99184, 512) /gpu:0
model/emb_1:0 (99184, 512) /gpu:0
model/emb_2:0 (99184, 512) /gpu:0
model/emb_3:0 (99184, 512) /gpu:0
model/emb_4:0 (99184, 512) /gpu:0
model/emb_5:0 (99184, 512) /gpu:0
model/emb_6:0 (99184, 512) /gpu:0
model/emb_7:0 (99184, 512) /gpu:0
model/lstm_0/LSTMCell/W_0:0 (1024, 8192) /gpu:0
model/lstm_0/LSTMCell/B:0 (8192,) /gpu:0
model/lstm_0/LSTMCell/W_P_0:0 (2048, 512) /gpu:0
model/softmax_w_0:0 (99184, 512) /gpu:0
model/softmax_w_1:0 (99184, 512) /gpu:0
model/softmax_w_2:0 (99184, 512) /gpu:0
model/softmax_w_3:0 (99184, 512) /gpu:0
model/softmax_w_4:0 (99184, 512) /gpu:0
model/softmax_w_5:0 (99184, 512) /gpu:0
model/softmax_w_6:0 (99184, 512) /gpu:0
model/softmax_w_7:0 (99184, 512) /gpu:0
model/softmax_b:0 (793470,) /gpu:0
LOCAL VARIABLES
model/model/state_0_0:0 (256, 2560) /gpu:0
model/model_1/state_1_0:0 (256, 2560) /gpu:0
model/model_2/state_2_0:0 (256, 2560) /gpu:0
model/model_3/state_3_0:0 (256, 2560) /gpu:0
model/model_4/state_4_0:0 (256, 2560) /gpu:0
model/model_5/state_5_0:0 (256, 2560) /gpu:0
model/model_6/state_6_0:0 (256, 2560) /gpu:0
model/model_7/state_7_0:0 (256, 2560) /gpu:0
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 1, time = 7.99s, wps = 5129, train loss = 13.3253
Iteration 2, time = 5.10s, wps = 8038, train loss = 13.0885
Iteration 3, time = 0.68s, wps = 60631, train loss = 12.6525
Iteration 4, time = 0.69s, wps = 59785, train loss = 44.7003
Iteration 5, time = 0.72s, wps = 57050, train loss = 99.6332
Iteration 6, time = 0.92s, wps = 44352, train loss = 146.4027
Iteration 7, time = 2.90s, wps = 14114, traiI tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 6182 get requests, put_count=6260 evicted_count=1000 eviction_rate=0.159744 and unsatisfied allocation rate=0.152863
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 256 to 281
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 75768 get requests, put_count=75774 evicted_count=1000 eviction_rate=0.0131971 and unsatisfied allocation rate=0.0138977
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 655 to 720
n loss = 167.1596
Iteration 8, time = 0.98s, wps = 41592, train loss = 85.5397
Iteration 9, time = 0.82s, wps = 50199, train loss = 76.3594
Iteration 20, time = 14.31s, wps = 31494, train loss = 12.3527
Iteration 40, time = 16.81s, wps = 48743, train loss = 10.7415
Iteration 60, time = 14.44s, wps = 56720, train loss = 10.0573
Iteration 80, time = 14.27s, wps = 57418, train loss = 9.7322
Iteration 100, time = 14.46s, wps = 56635, train loss = 10.5446
Iteration 120, time = 14.30s, wps = 57304, train loss = 8.6539
Iteration 140, time = 14.38s, wps = 56984, train loss = 8.5331
Iteration 160, time = 14.20s, wps = 57700, train loss = 8.1393
Iteration 180, time = 14.34s, wps = 57114, train loss = 7.9563
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 200, time = 16.11s, wps = 50858, train loss = 7.8630
Iteration 220, time = 14.44s, wps = 56719, train loss = 7.5412
Iteration 240, time = 14.19s, wps = 57721, train loss = 7.2629
Iteration 260, time = 14.35s, wps = 57080, train loss = 7.2078
Iteration 280, time = 14.66s, wps = 55873, train loss = 7.2311
Iteration 300, time = 14.66s, wps = 55896, train loss = 6.9560
Iteration 320, time = 14.63s, wps = 56008, train loss = 7.1666
Iteration 340, time = 14.69s, wps = 55766, train loss = 6.9118
Iteration 360, time = 14.39s, wps = 56935, train loss = 6.6318
Iteration 380, time = 14.37s, wps = 56992, train loss = 6.6191
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 400, time = 16.30s, wps = 50258, train loss = 6.4206
Iteration 420, time = 14.39s, wps = 56940, train loss = 6.4496
Iteration 440, time = 14.41s, wps = 56844, train loss = 6.3045
Iteration 460, time = 14.42s, wps = 56815, train loss = 6.2111
Iteration 480, time = 14.40s, wps = 56878, train loss = 6.0421
Iteration 500, time = 14.27s, wps = 57405, train loss = 6.1139
Iteration 520, time = 14.17s, wps = 57809, train loss = 5.9072
Iteration 540, time = 14.06s, wps = 58281, train loss = 6.0220
Iteration 560, time = 14.09s, wps = 58135, train loss = 5.8330
Iteration 580, time = 14.17s, wps = 57805, train loss = 5.7080
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 600, time = 15.91s, wps = 51481, train loss = 5.6274
Iteration 620, time = 14.12s, wps = 58022, train loss = 5.6171
Iteration 640, time = 14.07s, wps = 58237, train loss = 5.6539
Iteration 660, time = 14.16s, wps = 57861, train loss = 5.5423
Iteration 680, time = 14.20s, wps = 57695, train loss = 5.5449
Iteration 700, time = 14.38s, wps = 56955, train loss = 5.5174
Iteration 720, time = 14.60s, wps = 56099, train loss = 5.4389
Iteration 740, time = 14.24s, wps = 57531, train loss = 5.4450
Iteration 760, time = 14.60s, wps = 56111, train loss = 5.3765
Iteration 780, time = 14.54s, wps = 56360, train loss = 5.4696
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 800, time = 16.70s, wps = 49044, train loss = 5.3083
Iteration 820, time = 20.35s, wps = 40253, train loss = 5.2357
Iteration 840, time = 15.75s, wps = 52026, train loss = 5.2742
Iteration 860, time = 14.61s, wps = 56067, train loss = 5.1784
Iteration 880, time = 14.72s, wps = 55645, train loss = 5.1810
Iteration 900, time = 14.70s, wps = 55725, train loss = 5.1443
Iteration 920, time = 14.83s, wps = 55226, train loss = 5.1211
Iteration 940, time = 14.41s, wps = 56834, train loss = 5.1632
Iteration 960, time = 14.69s, wps = 55775, train loss = 5.0990
Iteration 980, time = 14.71s, wps = 55698, train loss = 5.0575
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 1000, time = 16.81s, wps = 48747, train loss = 5.0110
Iteration 1020, time = 15.14s, wps = 54112, train loss = 5.0043
Iteration 1040, time = 14.59s, wps = 56132, train loss = 5.0122
Iteration 1060, time = 14.91s, wps = 54933, train loss = 4.9698
Iteration 1080, time = 14.61s, wps = 56075, train loss = 4.9793
Iteration 1100, time = 14.49s, wps = 56535, train loss = 5.0996
Iteration 1120, time = 14.79s, wps = 55407, train loss = 4.9178
Iteration 1140, time = 14.60s, wps = 56128, train loss = 4.9055
Iteration 1160, time = 14.62s, wps = 56046, train loss = 4.9256
Iteration 1180, time = 14.81s, wps = 55325, train loss = 4.8962
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 1200, time = 16.71s, wps = 49038, train loss = 4.8052
Iteration 1220, time = 14.81s, wps = 55332, train loss = 4.7883
Iteration 1240, time = 14.46s, wps = 56648, train loss = 4.8479
Iteration 1260, time = 14.93s, wps = 54869, train loss = 4.7493
Iteration 1280, time = 14.41s, wps = 56844, train loss = 4.7861
Iteration 1300, time = 14.37s, wps = 57012, train loss = 4.7619
Iteration 1320, time = 14.56s, wps = 56280, train loss = 4.7264
Iteration 1340, time = 14.48s, wps = 56577, train loss = 4.7480
Iteration 1360, time = 14.63s, wps = 55992, train loss = 4.7366
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 1380, time = 16.61s, wps = 49312, train loss = 4.6950
Iteration 1400, time = 14.53s, wps = 56373, train loss = 4.5984
Iteration 1420, time = 14.42s, wps = 56793, train loss = 4.7151
Iteration 1440, time = 14.43s, wps = 56780, train loss = 4.6359
Iteration 1460, time = 14.37s, wps = 56999, train loss = 4.5934
Iteration 1480, time = 14.63s, wps = 55994, train loss = 4.6059
Iteration 1500, time = 14.52s, wps = 56402, train loss = 4.6255
Iteration 1520, time = 14.54s, wps = 56360, train loss = 4.6565
Iteration 1540, time = 14.68s, wps = 55807, train loss = 4.6285
Iteration 1560, time = 14.67s, wps = 55839, train loss = 4.6176
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 1580, time = 16.59s, wps = 49370, train loss = 4.5173
Iteration 1600, time = 14.56s, wps = 56266, train loss = 4.4892
Iteration 1620, time = 19.86s, wps = 41242, train loss = 4.4882
Iteration 1640, time = 16.01s, wps = 51183, train loss = 4.5011
Iteration 1660, time = 15.00s, wps = 54625, train loss = 4.4796
Iteration 1680, time = 14.51s, wps = 56462, train loss = 4.4801
Iteration 1700, time = 14.62s, wps = 56020, train loss = 4.4798
Iteration 1720, time = 14.45s, wps = 56709, train loss = 4.4613
Iteration 1740, time = 14.32s, wps = 57193, train loss = 4.4983
Iteration 1760, time = 14.57s, wps = 56224, train loss = 4.4885
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 1780, time = 16.70s, wps = 49048, train loss = 4.3627
Iteration 1800, time = 14.46s, wps = 56662, train loss = 4.3873
Iteration 1820, time = 14.54s, wps = 56327, train loss = 4.3473
Iteration 1840, time = 14.44s, wps = 56726, train loss = 4.3687
Iteration 1860, time = 14.70s, wps = 55710, train loss = 4.3933
Iteration 1880, time = 14.46s, wps = 56672, train loss = 4.3782
Iteration 1900, time = 14.48s, wps = 56585, train loss = 4.3867
Iteration 1920, time = 14.77s, wps = 55456, train loss = 4.4018
Iteration 1940, time = 15.01s, wps = 54579, train loss = 4.3818
Iteration 1960, time = 14.54s, wps = 56358, train loss = 4.3526
haibin: a new epoch just started
Processing file: /home/ubuntu/gbw-1/training-monolingual.tokenized.shuffled/news.en-00001-of-00100
Finished processing!
Iteration 1980, time = 16.45s, wps = 49814, train loss = 4.2414
Iteration 2000, time = 14.39s, wps = 56944, train loss = 4.2544
Iteration 2020, time = 14.48s, wps = 56583, train loss = 4.2464
Iteration 2040, time = 14.50s, wps = 56487, train loss = 4.2738
Iteration 2060, time = 14.41s, wps = 56862, train loss = 4.2641
Iteration 2080, time = 14.70s, wps = 55718, train loss = 4.2586
Iteration 2100, time = 14.46s, wps = 56659, train loss = 4.2819
Iteration 2120, time = 14.68s, wps = 55807, train loss = 4.2711
Traceback (most recent call last):
  File "single_lm_train.py", line 37, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File "single_lm_train.py", line 27, in main
    run_train(dataset, hps, FLAGS.logdir + "/train", ps_device="/gpu:0")
  File "/home/ubuntu/lm/run_utils.py", line 73, in run_train
    fetched = sess.run(fetches, {model.x: x, model.y: y, model.w: w})
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 766, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 964, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1014, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1021, in _do_call
    return fn(*args)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1003, in _run_fn
    status, run_metadata)
KeyboardInterrupt
